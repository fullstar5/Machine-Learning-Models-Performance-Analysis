{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def ascii_sum(s):\n",
    "    return np.sum([ord(c) for c in s])\n",
    "\n",
    "# read origin data\n",
    "train_data_original = pd.read_csv(\"data/TRAIN.csv\")\n",
    "val_data_original = pd.read_csv(\"data/VALIDATION.csv\")\n",
    "test_data_original = pd.read_csv(\"data/TEST_NO_LABELS.csv\")\n",
    "\n",
    "# add ASCII value of comment at each row\n",
    "train_data_original['ascii_sum'] = train_data_original['review-text-cleaned'].apply(ascii_sum)\n",
    "val_data_original['ascii_sum'] = val_data_original['review-text-cleaned'].apply(ascii_sum)\n",
    "test_data_original['ascii_sum'] = test_data_original['review-text-cleaned'].apply(ascii_sum)\n",
    "\n",
    "# create backup dataframes without actual comments, also normalization (min-max scaling)\n",
    "train_data_original_hiddenComment = train_data_original.drop(columns=['review-text-cleaned'])\n",
    "train_data_original_hiddenComment['ascii_sum'] = (train_data_original_hiddenComment['ascii_sum'] - train_data_original_hiddenComment['ascii_sum'].min()) / (train_data_original_hiddenComment['ascii_sum'].max() - train_data_original_hiddenComment['ascii_sum'].min())\n",
    "\n",
    "val_data_original_hiddenComment = val_data_original.drop(columns=['review-text-cleaned'])\n",
    "val_data_original_hiddenComment['ascii_sum'] = (val_data_original_hiddenComment['ascii_sum'] - val_data_original_hiddenComment['ascii_sum'].min()) / (val_data_original_hiddenComment['ascii_sum'].max() - val_data_original_hiddenComment['ascii_sum'].min())\n",
    "\n",
    "test_data_original_hiddenComment = test_data_original.drop(columns=['review-text-cleaned'])\n",
    "test_data_original_hiddenComment['ascii_sum'] = (test_data_original_hiddenComment['ascii_sum'] - test_data_original_hiddenComment['ascii_sum'].min()) / (test_data_original_hiddenComment['ascii_sum'].max() - test_data_original_hiddenComment['ascii_sum'].min())\n",
    "\n",
    "\n",
    "# extract labels from data\n",
    "train_labels = train_data_original[\"rating\"]\n",
    "val_labels = val_data_original[\"rating\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read embedding data and drop first column\n",
    "train_embeddings = pd.read_csv(\"data/384EMBEDDINGS_TRAIN.csv\")\n",
    "train_embeddings.drop(columns=train_embeddings.columns[0], axis=1, inplace=True)\n",
    "\n",
    "valid_embeddings = pd.read_csv(\"data/384EMBEDDINGS_VALIDATION.csv\")\n",
    "valid_embeddings.drop(columns=valid_embeddings.columns[0], axis=1, inplace=True)\n",
    "\n",
    "test_embeddings = pd.read_csv(\"data/384EMBEDDINGS_TEST.csv\")\n",
    "test_embeddings.drop(columns=test_embeddings.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tf-idf data and drop first column\n",
    "train_tfidf = pd.read_csv(\"data/TFIDF_TRAIN.csv\")\n",
    "train_tfidf.drop(columns=train_tfidf.columns[0], axis=1, inplace=True)\n",
    "\n",
    "valid_tfidf = pd.read_csv(\"data/TFIDF_VALIDATION.csv\")\n",
    "valid_tfidf.drop(columns=valid_tfidf.columns[0], axis=1, inplace=True)\n",
    "\n",
    "test_tfidf = pd.read_csv(\"data/TFIDF_TEST.csv\")\n",
    "test_tfidf.drop(columns=test_tfidf.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero R embedding, training time: 0.003957271575927734\n",
      "Zero R embedding, predicting time: 0.003995418548583984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1462\n",
      "           1       0.73      1.00      0.85      4038\n",
      "\n",
      "    accuracy                           0.73      5500\n",
      "   macro avg       0.37      0.50      0.42      5500\n",
      "weighted avg       0.54      0.73      0.62      5500\n",
      "\n",
      "One R embedding, training time (single round): 0.0\n",
      "One R embedding, predicting time (single round): 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.28      0.52      0.36      1462\n",
      "           1       0.75      0.51      0.61      4038\n",
      "\n",
      "    accuracy                           0.51      5500\n",
      "   macro avg       0.51      0.52      0.48      5500\n",
      "weighted avg       0.62      0.51      0.54      5500\n",
      "\n",
      "Random baseline embedding accuracy after 10 rounds 0.49958181818181807\n",
      "Zero R tf-idf, training time: 0.003997087478637695\n",
      "Zero R tf-idf, predicting time: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1462\n",
      "           1       0.73      1.00      0.85      4038\n",
      "\n",
      "    accuracy                           0.73      5500\n",
      "   macro avg       0.37      0.50      0.42      5500\n",
      "weighted avg       0.54      0.73      0.62      5500\n",
      "\n",
      "One R tf-idf, training time (single round): 0.0\n",
      "One R tf-idf, predicting time (single round): 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.27      0.51      0.35      1462\n",
      "           1       0.74      0.50      0.59      4038\n",
      "\n",
      "    accuracy                           0.50      5500\n",
      "   macro avg       0.50      0.50      0.47      5500\n",
      "weighted avg       0.61      0.50      0.53      5500\n",
      "\n",
      "Random baseline embedding accuracy after 10 rounds 0.49576363636363635\n",
      "Zero R origin, training time: 0.0\n",
      "Zero R origin, predicting time: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1462\n",
      "           1       0.73      1.00      0.85      4038\n",
      "\n",
      "    accuracy                           0.73      5500\n",
      "   macro avg       0.37      0.50      0.42      5500\n",
      "weighted avg       0.54      0.73      0.62      5500\n",
      "\n",
      "One R origin, training time (single round): 0.0019953250885009766\n",
      "One R origin, predicting time (single round): 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.27      0.51      0.35      1462\n",
      "           1       0.74      0.50      0.60      4038\n",
      "\n",
      "    accuracy                           0.50      5500\n",
      "   macro avg       0.50      0.51      0.48      5500\n",
      "weighted avg       0.61      0.50      0.53      5500\n",
      "\n",
      "Random baseline origin accuracy after 10 rounds 0.4999090909090908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# baseline classifier\n",
    "\n",
    "# zero r embedding\n",
    "ZEROclf = DummyClassifier(strategy=\"most_frequent\")\n",
    "start = time.time()\n",
    "ZEROclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"Zero R embedding, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = ZEROclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"Zero R embedding, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# one r embedding\n",
    "RANDOMclf = DummyClassifier(strategy=\"uniform\")\n",
    "start = time.time()\n",
    "RANDOMclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"R embedding, training time (single round): \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = RANDOMclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"R embedding, predicting time (single round): \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "random_scores = []\n",
    "for i in range(10):\n",
    "    RANDOMclf.fit(train_embeddings, train_labels)\n",
    "    random_scores.append(RANDOMclf.score(valid_embeddings, val_labels))\n",
    "print(\"Random baseline embedding accuracy after 10 rounds\", sum(random_scores) / 10.)\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "# zero r tf-idf\n",
    "ZEROclf = DummyClassifier(strategy=\"most_frequent\")\n",
    "start = time.time()\n",
    "ZEROclf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"Zero R tf-idf, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = ZEROclf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"Zero R tf-idf, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# one r tf-idf\n",
    "RANDOMclf = DummyClassifier(strategy=\"uniform\")\n",
    "start = time.time()\n",
    "RANDOMclf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"R tf-idf, training time (single round): \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = RANDOMclf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"R tf-idf, predicting time (single round): \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "random_scores = []\n",
    "for i in range(10):\n",
    "    RANDOMclf.fit(train_tfidf, train_labels)\n",
    "    random_scores.append(RANDOMclf.score(valid_tfidf, val_labels))\n",
    "print(\"Random baseline embedding accuracy after 10 rounds\", sum(random_scores) / 10.)\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "# zero r origin data\n",
    "ZEROclf = DummyClassifier(strategy=\"most_frequent\")\n",
    "start = time.time()\n",
    "ZEROclf.fit(train_data_original, train_labels)\n",
    "end = time.time()\n",
    "print(\"Zero R origin, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = ZEROclf.predict(val_data_original)\n",
    "end = time.time()\n",
    "print(\"Zero R origin, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# one r origin\n",
    "RANDOMclf = DummyClassifier(strategy=\"uniform\")\n",
    "start = time.time()\n",
    "RANDOMclf.fit(train_data_original, train_labels)\n",
    "end = time.time()\n",
    "print(\"R origin, training time (single round): \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = RANDOMclf.predict(val_data_original)\n",
    "end = time.time()\n",
    "print(\"R origin, predicting time (single round): \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "random_scores = []\n",
    "for i in range(10):\n",
    "    RANDOMclf.fit(train_data_original, train_labels)\n",
    "    random_scores.append(RANDOMclf.score(val_data_original, val_labels))\n",
    "print(\"Random baseline origin accuracy after 10 rounds\", sum(random_scores) / 10.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Classification ML algorithm and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf Multinomial Naive Bayes alpha 0.1, training time: 0.06585693359375\n",
      "tf-idf Multinomial Naive Bayes, predicting time: 0.010776996612548828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.66      0.75      1462\n",
      "           1       0.89      0.97      0.92      4038\n",
      "\n",
      "    accuracy                           0.88      5500\n",
      "   macro avg       0.88      0.81      0.84      5500\n",
      "weighted avg       0.88      0.88      0.88      5500\n",
      "\n",
      "tf-idf Multinomial Naive Bayes alpha 0.2, training time: 0.055933237075805664\n",
      "tf-idf Multinomial Naive Bayes, predicting time: 0.01591944694519043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.66      0.75      1462\n",
      "           1       0.89      0.97      0.92      4038\n",
      "\n",
      "    accuracy                           0.88      5500\n",
      "   macro avg       0.88      0.81      0.84      5500\n",
      "weighted avg       0.88      0.88      0.88      5500\n",
      "\n",
      "tf-idf Multinomial Naive Bayes alpha 0.3, training time: 0.06283092498779297\n",
      "tf-idf Multinomial Naive Bayes, predicting time: 0.007988214492797852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.66      0.75      1462\n",
      "           1       0.89      0.97      0.92      4038\n",
      "\n",
      "    accuracy                           0.88      5500\n",
      "   macro avg       0.88      0.81      0.84      5500\n",
      "weighted avg       0.88      0.88      0.88      5500\n",
      "\n",
      "tf-idf Multinomial Naive Bayes alpha 0.4, training time: 0.06056022644042969\n",
      "tf-idf Multinomial Naive Bayes, predicting time: 0.012215137481689453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.66      0.75      1462\n",
      "           1       0.89      0.97      0.92      4038\n",
      "\n",
      "    accuracy                           0.88      5500\n",
      "   macro avg       0.88      0.81      0.84      5500\n",
      "weighted avg       0.88      0.88      0.88      5500\n",
      "\n",
      "tf-idf Multinomial Naive Bayes alpha 0.5, training time: 0.06306147575378418\n",
      "tf-idf Multinomial Naive Bayes, predicting time: 0.012636899948120117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.66      0.75      1462\n",
      "           1       0.89      0.97      0.92      4038\n",
      "\n",
      "    accuracy                           0.88      5500\n",
      "   macro avg       0.88      0.81      0.84      5500\n",
      "weighted avg       0.88      0.88      0.88      5500\n",
      "\n",
      "tf-idf Multinomial Naive Bayes alpha 0.6, training time: 0.05732417106628418\n",
      "tf-idf Multinomial Naive Bayes, predicting time: 0.011939287185668945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.66      0.75      1462\n",
      "           1       0.89      0.97      0.92      4038\n",
      "\n",
      "    accuracy                           0.88      5500\n",
      "   macro avg       0.88      0.81      0.84      5500\n",
      "weighted avg       0.88      0.88      0.88      5500\n",
      "\n",
      "tf-idf Multinomial Naive Bayes alpha 0.7, training time: 0.06395530700683594\n",
      "tf-idf Multinomial Naive Bayes, predicting time: 0.013650655746459961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.66      0.75      1462\n",
      "           1       0.89      0.97      0.92      4038\n",
      "\n",
      "    accuracy                           0.88      5500\n",
      "   macro avg       0.88      0.81      0.84      5500\n",
      "weighted avg       0.88      0.88      0.88      5500\n",
      "\n",
      "tf-idf Multinomial Naive Bayes alpha 0.8, training time: 0.06566548347473145\n",
      "tf-idf Multinomial Naive Bayes, predicting time: 0.007988452911376953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.66      0.75      1462\n",
      "           1       0.89      0.97      0.92      4038\n",
      "\n",
      "    accuracy                           0.88      5500\n",
      "   macro avg       0.88      0.81      0.84      5500\n",
      "weighted avg       0.88      0.88      0.88      5500\n",
      "\n",
      "tf-idf Multinomial Naive Bayes alpha 0.9, training time: 0.0639185905456543\n",
      "tf-idf Multinomial Naive Bayes, predicting time: 0.011980533599853516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.66      0.75      1462\n",
      "           1       0.89      0.97      0.92      4038\n",
      "\n",
      "    accuracy                           0.88      5500\n",
      "   macro avg       0.88      0.81      0.84      5500\n",
      "weighted avg       0.88      0.88      0.88      5500\n",
      "\n",
      "tf-idf Gaussian Naive Bayes, training time: 0.43671464920043945\n",
      "tf-idf Gaussian Naive Bayes, predicting time: 0.061937570571899414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.89      0.77      1462\n",
      "           1       0.96      0.84      0.90      4038\n",
      "\n",
      "    accuracy                           0.86      5500\n",
      "   macro avg       0.82      0.87      0.83      5500\n",
      "weighted avg       0.88      0.86      0.86      5500\n",
      "\n",
      "embeddings Gaussian Naive Bayes, training time: 0.30039000511169434\n",
      "embeddings Gaussian Naive Bayes, predicting time: 0.04715871810913086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.89      0.78      1462\n",
      "           1       0.96      0.86      0.90      4038\n",
      "\n",
      "    accuracy                           0.87      5500\n",
      "   macro avg       0.82      0.87      0.84      5500\n",
      "weighted avg       0.89      0.87      0.87      5500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial and Gaussian NB in embedding and tf-idf data, also compare training and predicting time\n",
    "\n",
    "# MNB, tf-idf, alpha 0.1\n",
    "MNB_clf = MultinomialNB(alpha=0.1)\n",
    "start = time.time()\n",
    "MNB_clf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes alpha 0.1, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MNB_clf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes, predicting time: \" + str(end - start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# MNB, tf-idf alpha 0.2\n",
    "MNB_clf = MultinomialNB(alpha=0.2)\n",
    "start = time.time()\n",
    "MNB_clf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes alpha 0.2, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MNB_clf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes, predicting time: \" + str(end - start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# MNB, tf-idf alpha 0.3\n",
    "MNB_clf = MultinomialNB(alpha=0.3)\n",
    "start = time.time()\n",
    "MNB_clf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes alpha 0.3, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MNB_clf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes, predicting time: \" + str(end - start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# MNB, tf-idf alpha 0.4\n",
    "MNB_clf = MultinomialNB(alpha=0.4)\n",
    "start = time.time()\n",
    "MNB_clf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes alpha 0.4, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MNB_clf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes, predicting time: \" + str(end - start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# MNB, tf-idf alpha 0.5\n",
    "MNB_clf = MultinomialNB(alpha=0.5)\n",
    "start = time.time()\n",
    "MNB_clf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes alpha 0.5, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MNB_clf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes, predicting time: \" + str(end - start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# MNB, tf-idf alpha 0.6\n",
    "MNB_clf = MultinomialNB(alpha=0.6)\n",
    "start = time.time()\n",
    "MNB_clf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes alpha 0.6, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MNB_clf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes, predicting time: \" + str(end - start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# MNB, tf-idf alpha 0.7\n",
    "MNB_clf = MultinomialNB(alpha=0.7)\n",
    "start = time.time()\n",
    "MNB_clf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes alpha 0.7, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MNB_clf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes, predicting time: \" + str(end - start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# MNB, tf-idf alpha 0.8\n",
    "MNB_clf = MultinomialNB(alpha=0.8)\n",
    "start = time.time()\n",
    "MNB_clf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes alpha 0.8, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MNB_clf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes, predicting time: \" + str(end - start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# MNB, tf-idf alpha 0.9\n",
    "MNB_clf = MultinomialNB(alpha=0.9)\n",
    "start = time.time()\n",
    "MNB_clf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes alpha 0.9, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MNB_clf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes, predicting time: \" + str(end - start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "# GNB, tf-idf\n",
    "GNB_clf = GaussianNB()\n",
    "start = time.time()\n",
    "GNB_clf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Gaussian Naive Bayes, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = GNB_clf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Gaussian Naive Bayes, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# GNB, embedding\n",
    "GNB_clf = GaussianNB()\n",
    "start = time.time()\n",
    "GNB_clf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings Gaussian Naive Bayes, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = GNB_clf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings Gaussian Naive Bayes, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "\n",
    "# embedding data cannot be used in MNB, as MNB require positive integer\n",
    "# origin data cannot be used in both GNB and MNB, as the dataset contains negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings Gaussian Naive Bayes, training time: 0.6130189895629883\n",
      "embeddings Gaussian Naive Bayes, predicting time: 0.04522967338562012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      1462\n",
      "           1       1.00      1.00      1.00      4038\n",
      "\n",
      "    accuracy                           1.00      5500\n",
      "   macro avg       1.00      1.00      1.00      5500\n",
      "weighted avg       1.00      1.00      1.00      5500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test cell\n",
    "# GNB_clf = GaussianNB()\n",
    "# start = time.time()\n",
    "# GNB_clf.fit(train_data_original_hiddenComment, train_labels)\n",
    "# end = time.time()\n",
    "# print(\"embeddings Gaussian Naive Bayes, training time: \" + str(end-start))\n",
    "# start = time.time()\n",
    "# valid_pred = GNB_clf.predict(val_data_original_hiddenComment)\n",
    "# end = time.time()\n",
    "# print(\"embeddings Gaussian Naive Bayes, predicting time: \" + str(end-start))\n",
    "# print(classification_report(val_labels, valid_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings Logistic Regression (800 iter), training time: 2.216745138168335\n",
      "embeddings Logistic Regression (800 iter), predicting time: 0.006026268005371094\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.83      0.85      1462\n",
      "           1       0.94      0.95      0.95      4038\n",
      "\n",
      "    accuracy                           0.92      5500\n",
      "   macro avg       0.90      0.89      0.90      5500\n",
      "weighted avg       0.92      0.92      0.92      5500\n",
      "\n",
      "embeddings Logistic Regression (700 iter), training time: 2.2006094455718994\n",
      "embeddings Logistic Regression (700 iter), predicting time: 0.007990360260009766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.83      0.85      1462\n",
      "           1       0.94      0.95      0.95      4038\n",
      "\n",
      "    accuracy                           0.92      5500\n",
      "   macro avg       0.90      0.89      0.90      5500\n",
      "weighted avg       0.92      0.92      0.92      5500\n",
      "\n",
      "embeddings Logistic Regression (600 iter), training time: 2.2303860187530518\n",
      "embeddings Logistic Regression (600 iter), predicting time: 0.00798940658569336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.83      0.85      1462\n",
      "           1       0.94      0.95      0.95      4038\n",
      "\n",
      "    accuracy                           0.92      5500\n",
      "   macro avg       0.90      0.89      0.90      5500\n",
      "weighted avg       0.92      0.92      0.92      5500\n",
      "\n",
      "tf-idf Logistic Regression (800 iter), training time: 1.360274314880371\n",
      "tf-idf Logistic Regression (800 iter), predicting time: 0.007987737655639648\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.85      0.83      1462\n",
      "           1       0.94      0.93      0.94      4038\n",
      "\n",
      "    accuracy                           0.91      5500\n",
      "   macro avg       0.88      0.89      0.88      5500\n",
      "weighted avg       0.91      0.91      0.91      5500\n",
      "\n",
      "tf-idf Logistic Regression (700 iter), training time: 1.3017425537109375\n",
      "tf-idf Logistic Regression (700 iter), predicting time: 0.011986732482910156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.85      0.83      1462\n",
      "           1       0.94      0.93      0.94      4038\n",
      "\n",
      "    accuracy                           0.91      5500\n",
      "   macro avg       0.88      0.89      0.88      5500\n",
      "weighted avg       0.91      0.91      0.91      5500\n",
      "\n",
      "tf-idf Logistic Regression (600 iter), training time: 1.3096261024475098\n",
      "tf-idf Logistic Regression (600 iter), predicting time: 0.005019664764404297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.85      0.83      1462\n",
      "           1       0.94      0.93      0.94      4038\n",
      "\n",
      "    accuracy                           0.91      5500\n",
      "   macro avg       0.88      0.89      0.88      5500\n",
      "weighted avg       0.91      0.91      0.91      5500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin(hidden comments) Logistic Regression(penalty l1), training time: 6.375406980514526\n",
      "origin(hidden comments) Logistic Regression(penalty l1), predicting time: 0.001993417739868164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.27      1.00      0.42      1462\n",
      "           1       0.00      0.00      0.00      4038\n",
      "\n",
      "    accuracy                           0.27      5500\n",
      "   macro avg       0.13      0.50      0.21      5500\n",
      "weighted avg       0.07      0.27      0.11      5500\n",
      "\n",
      "origin(hidden comments) Logistic Regression(penalty l2), training time: 5.7854180335998535\n",
      "origin(hidden comments) Logistic Regression(penalty l2), predicting time: 0.0019948482513427734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.27      1.00      0.42      1462\n",
      "           1       0.00      0.00      0.00      4038\n",
      "\n",
      "    accuracy                           0.27      5500\n",
      "   macro avg       0.13      0.50      0.21      5500\n",
      "weighted avg       0.07      0.27      0.11      5500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# logistic regression in embedding, tf-idf, origin data\n",
    "# nearly no change in classification report, minor change in training/predicting time\n",
    "\n",
    "# 800 iter embedding\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "LRclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings Logistic Regression (800 iter), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings Logistic Regression (800 iter), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 700 iter embedding\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=700)\n",
    "start = time.time()\n",
    "LRclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings Logistic Regression (700 iter), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings Logistic Regression (700 iter), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 600 iter embedding\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=600)\n",
    "start = time.time()\n",
    "LRclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings Logistic Regression (600 iter), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings Logistic Regression (600 iter), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "# 800 iter tf-idf\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "LRclf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (800 iter), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (800 iter), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 700 iter tf-idf\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=700)\n",
    "start = time.time()\n",
    "LRclf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (700 iter), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (700 iter), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 600 iter tf-idf\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=600)\n",
    "start = time.time()\n",
    "LRclf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (600 iter), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (600 iter), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "# 800 iter origin (over-fitting due to unique ASCII value in each comment)\n",
    "\n",
    "# overcome over-fitting by using regularization (setting penalty l1)\n",
    "LRclf = LogisticRegression(penalty='l1', C=1.0, solver='saga', random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "LRclf.fit(train_data_original_hiddenComment, train_labels)\n",
    "end = time.time()\n",
    "print(\"origin(hidden comments) Logistic Regression(penalty l1), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(val_data_original_hiddenComment)\n",
    "end = time.time()\n",
    "print(\"origin(hidden comments) Logistic Regression(penalty l1), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# overcome over-fitting by using regularization (setting penalty l2)\n",
    "LRclf = LogisticRegression(penalty='l2', C=1.0, solver='saga', random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "LRclf.fit(train_data_original_hiddenComment, train_labels)\n",
    "end = time.time()\n",
    "print(\"origin(hidden comments) Logistic Regression(penalty l2), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(val_data_original_hiddenComment)\n",
    "end = time.time()\n",
    "print(\"origin(hidden comments) Logistic Regression(penalty l2), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding Logistic Regression (balanced), training time: 2.1076748371124268\n",
      "embedding Logistic Regression (balanced), predicting time: 0.010010004043579102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.94      0.85      1462\n",
      "           1       0.98      0.90      0.93      4038\n",
      "\n",
      "    accuracy                           0.91      5500\n",
      "   macro avg       0.87      0.92      0.89      5500\n",
      "weighted avg       0.92      0.91      0.91      5500\n",
      "\n",
      "tf-idf Logistic Regression (balanced), training time: 1.2545523643493652\n",
      "tf-idf Logistic Regression (balanced), predicting time: 0.011435747146606445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.92      0.82      1462\n",
      "           1       0.97      0.88      0.92      4038\n",
      "\n",
      "    accuracy                           0.89      5500\n",
      "   macro avg       0.85      0.90      0.87      5500\n",
      "weighted avg       0.91      0.89      0.89      5500\n",
      "\n",
      "embedding Logistic Regression (1:0.2 and -1:0.8), training time: 1.7105629444122314\n",
      "embedding Logistic Regression (1:0.2 and -1:0.8), predicting time: 0.007988691329956055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.96      0.83      1462\n",
      "           1       0.98      0.87      0.92      4038\n",
      "\n",
      "    accuracy                           0.89      5500\n",
      "   macro avg       0.86      0.92      0.88      5500\n",
      "weighted avg       0.92      0.89      0.90      5500\n",
      "\n",
      "tf-idf Logistic Regression (1:0.2 and -1:0.8), training time: 1.4157710075378418\n",
      "tf-idf Logistic Regression (1:0.2 and -1:0.8), predicting time: 0.007987737655639648\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.94      0.79      1462\n",
      "           1       0.98      0.85      0.91      4038\n",
      "\n",
      "    accuracy                           0.87      5500\n",
      "   macro avg       0.83      0.89      0.85      5500\n",
      "weighted avg       0.90      0.87      0.88      5500\n",
      "\n",
      "embedding Logistic Regression (1:0.3, -1:0.7), training time: 1.555835485458374\n",
      "embedding Logistic Regression (1:0.3, -1:0.7), predicting time: 0.011984825134277344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.94      0.85      1462\n",
      "           1       0.98      0.90      0.94      4038\n",
      "\n",
      "    accuracy                           0.91      5500\n",
      "   macro avg       0.87      0.92      0.89      5500\n",
      "weighted avg       0.92      0.91      0.91      5500\n",
      "\n",
      "tf-idf Logistic Regression (1:0.3, -1:0.7), training time: 1.618729591369629\n",
      "tf-idf Logistic Regression (1:0.3, -1:0.7), predicting time: 0.007987260818481445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.92      0.82      1462\n",
      "           1       0.97      0.89      0.92      4038\n",
      "\n",
      "    accuracy                           0.89      5500\n",
      "   macro avg       0.86      0.90      0.87      5500\n",
      "weighted avg       0.91      0.89      0.90      5500\n",
      "\n",
      "embedding Logistic Regression (1:0.4, -1:0.6), training time: 1.7365665435791016\n",
      "embedding Logistic Regression (1:0.4, -1:0.6), predicting time: 0.005530595779418945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.91      0.85      1462\n",
      "           1       0.97      0.92      0.94      4038\n",
      "\n",
      "    accuracy                           0.91      5500\n",
      "   macro avg       0.88      0.91      0.90      5500\n",
      "weighted avg       0.92      0.91      0.92      5500\n",
      "\n",
      "tf-idf Logistic Regression (1:0.4, -1:0.6), training time: 1.8969814777374268\n",
      "tf-idf Logistic Regression (1:0.4, -1:0.6), predicting time: 0.008979082107543945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.88      0.83      1462\n",
      "           1       0.95      0.91      0.93      4038\n",
      "\n",
      "    accuracy                           0.90      5500\n",
      "   macro avg       0.87      0.90      0.88      5500\n",
      "weighted avg       0.91      0.90      0.91      5500\n",
      "\n",
      "origin Logistic Regression (1:0.4, -1:0.6), training time: 5.388858318328857\n",
      "origin Logistic Regression (1:0.4, -1:0.6), predicting time: 0.003992795944213867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.27      1.00      0.42      1462\n",
      "           1       0.00      0.00      0.00      4038\n",
      "\n",
      "    accuracy                           0.27      5500\n",
      "   macro avg       0.13      0.50      0.21      5500\n",
      "weighted avg       0.07      0.27      0.11      5500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression, adjust class_weight parameter\n",
    "# the larger weight of 1 (in range 0 to 0.5), the better performance (slightly)\n",
    "\n",
    "# embedding, balanced\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800, class_weight=\"balanced\")\n",
    "start = time.time()\n",
    "LRclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embedding Logistic Regression (balanced), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embedding Logistic Regression (balanced), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# tf-idf, balanced\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800, class_weight=\"balanced\")\n",
    "start = time.time()\n",
    "LRclf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (balanced), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (balanced), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "weight = {1:0.2, -1:0.8}\n",
    "# embedding, with weight 1:0.2 and -1:0.8\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800, class_weight=weight)\n",
    "start = time.time()\n",
    "LRclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embedding Logistic Regression (1:0.2 and -1:0.8), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embedding Logistic Regression (1:0.2 and -1:0.8), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# tf-idf, 1:0.2, -1:0.8\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800, class_weight=weight)\n",
    "start = time.time()\n",
    "LRclf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (1:0.2 and -1:0.8), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (1:0.2 and -1:0.8), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "weight = {1:0.3, -1:0.7}\n",
    "# embedding, with weight 1:0.3 and -1:0.7\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800, class_weight=weight)\n",
    "start = time.time()\n",
    "LRclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embedding Logistic Regression (1:0.3, -1:0.7), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embedding Logistic Regression (1:0.3, -1:0.7), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# tf-idf, 1:0.3, -1:0.7\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800, class_weight=weight)\n",
    "start = time.time()\n",
    "LRclf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (1:0.3, -1:0.7), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (1:0.3, -1:0.7), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "weight = {1:0.4, -1:0.6}\n",
    "# embedding, with weight 1:0.4, -1:0.6\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800, class_weight=weight)\n",
    "start = time.time()\n",
    "LRclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embedding Logistic Regression (1:0.4, -1:0.6), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embedding Logistic Regression (1:0.4, -1:0.6), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# tf-idf, 1:0.4, -1:0.6\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800, class_weight=weight)\n",
    "start = time.time()\n",
    "LRclf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (1:0.4, -1:0.6), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (1:0.4, -1:0.6), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "# origin, 1:0.4, -1:0.6 (over-fitting due to unique ASCII value in each comment)\n",
    "LRclf = LogisticRegression(penalty='l2', C=1.0, solver='saga', random_state=42, max_iter=800, class_weight=weight)\n",
    "start = time.time()\n",
    "LRclf.fit(train_data_original_hiddenComment, train_labels)\n",
    "end = time.time()\n",
    "print(\"origin Logistic Regression (1:0.4, -1:0.6), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(val_data_original_hiddenComment)\n",
    "end = time.time()\n",
    "print(\"origin Logistic Regression (1:0.4, -1:0.6), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings KNN (8 neighbors), training time: 0.09986758232116699\n",
      "embeddings KNN (8 neighbors), predicting time: 13.544358968734741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.69      0.76      1462\n",
      "           1       0.90      0.95      0.92      4038\n",
      "\n",
      "    accuracy                           0.88      5500\n",
      "   macro avg       0.87      0.82      0.84      5500\n",
      "weighted avg       0.88      0.88      0.88      5500\n",
      "\n",
      "embeddings KNN (9 neighbors), training time: 0.7937304973602295\n",
      "embeddings KNN (9 neighbors), predicting time: 7.636733293533325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.69      0.76      1462\n",
      "           1       0.90      0.95      0.92      4038\n",
      "\n",
      "    accuracy                           0.88      5500\n",
      "   macro avg       0.87      0.82      0.84      5500\n",
      "weighted avg       0.88      0.88      0.88      5500\n",
      "\n",
      "embeddings KNN (10 neighbors), training time: 0.1732175350189209\n",
      "embeddings KNN (10 neighbors), predicting time: 6.22006368637085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.69      0.76      1462\n",
      "           1       0.90      0.95      0.92      4038\n",
      "\n",
      "    accuracy                           0.88      5500\n",
      "   macro avg       0.87      0.82      0.84      5500\n",
      "weighted avg       0.88      0.88      0.88      5500\n",
      "\n",
      "tf-idf KNN (8 neighbors), training time: 0.3305246829986572\n",
      "tf-idf KNN (8 neighbors), predicting time: 6.718110799789429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.68      0.69      1462\n",
      "           1       0.88      0.90      0.89      4038\n",
      "\n",
      "    accuracy                           0.84      5500\n",
      "   macro avg       0.80      0.79      0.79      5500\n",
      "weighted avg       0.84      0.84      0.84      5500\n",
      "\n",
      "tf-idf KNN (9 neighbors), training time: 0.11531805992126465\n",
      "tf-idf KNN (9 neighbors), predicting time: 6.777039051055908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.60      0.67      1462\n",
      "           1       0.86      0.93      0.90      4038\n",
      "\n",
      "    accuracy                           0.84      5500\n",
      "   macro avg       0.81      0.76      0.78      5500\n",
      "weighted avg       0.84      0.84      0.84      5500\n",
      "\n",
      "tf-idf KNN (10 neighbors), training time: 0.10385894775390625\n",
      "tf-idf KNN (10 neighbors), predicting time: 6.577538967132568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.59      0.66      1462\n",
      "           1       0.86      0.93      0.90      4038\n",
      "\n",
      "    accuracy                           0.84      5500\n",
      "   macro avg       0.81      0.76      0.78      5500\n",
      "weighted avg       0.83      0.84      0.83      5500\n",
      "\n",
      "origin(hidden comments) KNN (8 neighbors), training time: 0.01601266860961914\n",
      "origin KNN(hidden comments) (8 neighbors), predicting time: 2.7155041694641113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1462\n",
      "           1       0.73      1.00      0.85      4038\n",
      "\n",
      "    accuracy                           0.73      5500\n",
      "   macro avg       0.37      0.50      0.42      5500\n",
      "weighted avg       0.54      0.73      0.62      5500\n",
      "\n",
      "origin(hidden comments) KNN (9 neighbors), training time: 0.005239248275756836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin KNN(hidden comments) (9 neighbors), predicting time: 2.9079182147979736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1462\n",
      "           1       0.73      1.00      0.85      4038\n",
      "\n",
      "    accuracy                           0.73      5500\n",
      "   macro avg       0.37      0.50      0.42      5500\n",
      "weighted avg       0.54      0.73      0.62      5500\n",
      "\n",
      "origin(hidden comments) KNN (10 neighbors), training time: 0.009181737899780273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin KNN(hidden comments) (10 neighbors), predicting time: 3.2142648696899414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1462\n",
      "           1       0.73      1.00      0.85      4038\n",
      "\n",
      "    accuracy                           0.73      5500\n",
      "   macro avg       0.37      0.50      0.42      5500\n",
      "weighted avg       0.54      0.73      0.62      5500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# KNN in different neighbors\n",
    "\n",
    "# 8 neighbors embedding\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=8, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings KNN (8 neighbors), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings KNN (8 neighbors), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 9 neighbors embedding\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=9, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings KNN (9 neighbors), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings KNN (9 neighbors), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 10 neighbors embedding\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=10, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings KNN (10 neighbors), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings KNN (10 neighbors), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "# 8 neighbors tf-idf\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=8, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf KNN (8 neighbors), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf KNN (8 neighbors), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 9 neighbors tf-idf\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=9, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf KNN (9 neighbors), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf KNN (9 neighbors), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 10 neighbors tf-idf\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=10, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(train_tfidf, train_labels)\n",
    "end = time.time()\n",
    "print(\"tf-idf KNN (10 neighbors), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(valid_tfidf)\n",
    "end = time.time()\n",
    "print(\"tf-idf KNN (10 neighbors), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "# 8 neighbors origin(hidden comments)\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=8, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(train_data_original_hiddenComment, train_labels)\n",
    "end = time.time()\n",
    "print(\"origin(hidden comments) KNN (8 neighbors), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(val_data_original_hiddenComment)\n",
    "end = time.time()\n",
    "print(\"origin KNN(hidden comments) (8 neighbors), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 9 neighbors origin(hidden comments)\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=9, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(train_data_original_hiddenComment, train_labels)\n",
    "end = time.time()\n",
    "print(\"origin(hidden comments) KNN (9 neighbors), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(val_data_original_hiddenComment)\n",
    "end = time.time()\n",
    "print(\"origin KNN(hidden comments) (9 neighbors), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 10 neighbors origin(hidden comments)\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=10, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(train_data_original_hiddenComment, train_labels)\n",
    "end = time.time()\n",
    "print(\"origin(hidden comments) KNN (10 neighbors), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(val_data_original_hiddenComment)\n",
    "end = time.time()\n",
    "print(\"origin KNN(hidden comments) (10 neighbors), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings MLPClassifier (200 hidden layer), training time: 177.16714453697205\n",
      "embeddings MLPClassifier (200 hidden layer), predicting time: 0.03628230094909668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.85      0.85      1462\n",
      "           1       0.94      0.94      0.94      4038\n",
      "\n",
      "    accuracy                           0.92      5500\n",
      "   macro avg       0.90      0.90      0.90      5500\n",
      "weighted avg       0.92      0.92      0.92      5500\n",
      "\n",
      "embeddings MLPClassifier (300 hidden layer), training time: 263.7728865146637\n",
      "embeddings MLPClassifier (300 hidden layer), predicting time: 0.13129615783691406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.85      0.84      1462\n",
      "           1       0.94      0.94      0.94      4038\n",
      "\n",
      "    accuracy                           0.92      5500\n",
      "   macro avg       0.89      0.89      0.89      5500\n",
      "weighted avg       0.92      0.92      0.92      5500\n",
      "\n",
      "embeddings MLPClassifier (400 hidden layer), training time: 335.2608664035797\n",
      "embeddings MLPClassifier (400 hidden layer), predicting time: 0.3408348560333252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.83      0.84      1462\n",
      "           1       0.94      0.95      0.94      4038\n",
      "\n",
      "    accuracy                           0.92      5500\n",
      "   macro avg       0.90      0.89      0.89      5500\n",
      "weighted avg       0.92      0.92      0.92      5500\n",
      "\n",
      "embeddings MLPClassifier (500 hidden layer), training time: 404.31888604164124\n",
      "embeddings MLPClassifier (500 hidden layer), predicting time: 0.2448441982269287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.89      0.85      1462\n",
      "           1       0.96      0.93      0.94      4038\n",
      "\n",
      "    accuracy                           0.92      5500\n",
      "   macro avg       0.89      0.91      0.90      5500\n",
      "weighted avg       0.92      0.92      0.92      5500\n",
      "\n",
      "embeddings MLPClassifier (invscaling), training time: 158.65571856498718\n",
      "embeddings MLPClassifier (invscaling), predicting time: 0.027960538864135742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.85      0.85      1462\n",
      "           1       0.94      0.94      0.94      4038\n",
      "\n",
      "    accuracy                           0.92      5500\n",
      "   macro avg       0.90      0.90      0.90      5500\n",
      "weighted avg       0.92      0.92      0.92      5500\n",
      "\n",
      "embeddings MLPClassifier (adaptive), training time: 163.31564784049988\n",
      "embeddings MLPClassifier (adaptive), predicting time: 0.031248807907104492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.85      0.85      1462\n",
      "           1       0.94      0.94      0.94      4038\n",
      "\n",
      "    accuracy                           0.92      5500\n",
      "   macro avg       0.90      0.90      0.90      5500\n",
      "weighted avg       0.92      0.92      0.92      5500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLPClassifier in different hidden layers\n",
    "\n",
    "# 200 hidden layer\n",
    "MLPclf = MLPClassifier(hidden_layer_sizes=200, random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "MLPclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (200 hidden layer), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MLPclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (200 hidden layer), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 300 hidden layer\n",
    "MLPclf = MLPClassifier(hidden_layer_sizes=300, random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "MLPclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (300 hidden layer), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MLPclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (300 hidden layer), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 400 hidden layer\n",
    "MLPclf = MLPClassifier(hidden_layer_sizes=400, random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "MLPclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (400 hidden layer), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MLPclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (400 hidden layer), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# 500 hidden layer\n",
    "MLPclf = MLPClassifier(hidden_layer_sizes=500, random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "MLPclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (500 hidden layer), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MLPclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (500 hidden layer), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "# MLPClassifier in different learning rate\n",
    "\n",
    "# invscaling learning rate\n",
    "MLPclf = MLPClassifier(hidden_layer_sizes=200, learning_rate='invscaling' ,random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "MLPclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (invscaling), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MLPclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (invscaling), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))\n",
    "\n",
    "# adaptive learning rate\n",
    "MLPclf = MLPClassifier(hidden_layer_sizes=200, learning_rate='adaptive' ,random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "MLPclf.fit(train_embeddings, train_labels)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (adaptive), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MLPclf.predict(valid_embeddings)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (adaptive), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_labels, valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Research Question 1: Gender Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current number of male data (validation): 3584\n",
      "current number of female data (validation): 1497\n",
      "current gender ratio (validation): 1 - 2.394121576486306\n",
      "current number of male data (training): 27511\n",
      "current number of female data (training): 12141\n",
      "current gender ratio (training): 1 - 2.265958323037641\n"
     ]
    }
   ],
   "source": [
    "# male and female data processing (in validation and origin dataset)\n",
    "\n",
    "# male/female data count in validation dataset\n",
    "male_data_original = val_data_original_hiddenComment[val_data_original_hiddenComment['dr_id_gender'] == 1]\n",
    "val_male_label = male_data_original['rating']\n",
    "female_data_original = val_data_original_hiddenComment[val_data_original_hiddenComment['dr_id_gender'] == 0]\n",
    "val_female_label = female_data_original['rating']\n",
    "# all positive/negative comment from male data in validation dataset\n",
    "male_data_positive = male_data_original[male_data_original['rating'] == 1]\n",
    "male_data_negative = male_data_original[male_data_original['rating'] == -1]\n",
    "female_data_positive = female_data_original[female_data_original['rating'] == 1]\n",
    "female_data_negative = female_data_original[female_data_original['rating'] == -1]\n",
    "# calculate current gender ratio (male:female) in validation dataset\n",
    "print(\"current number of male data (validation): \" + str(len(male_data_original)))\n",
    "print(\"current number of female data (validation): \" + str(len(female_data_original)))\n",
    "print(\"current gender ratio (validation): 1 - \" + str(len(male_data_original) / len(female_data_original)))\n",
    "\n",
    "# male/female data count in training dataset\n",
    "male_data_original_training = train_data_original_hiddenComment[train_data_original_hiddenComment['dr_id_gender'] == 1]\n",
    "training_male_label = male_data_original_training['rating']\n",
    "female_data_original_training = train_data_original_hiddenComment[train_data_original_hiddenComment['dr_id_gender'] == 0]\n",
    "training_female_label = female_data_original_training['rating']\n",
    "# all positive/negative comment from male data in training dataset\n",
    "male_data_positive_training = male_data_original_training[male_data_original_training['rating'] == 1]\n",
    "male_data_negative_training = male_data_original_training[male_data_original_training['rating'] == -1]\n",
    "female_data_positive_training = female_data_original_training[female_data_original_training['rating'] == 1]\n",
    "female_data_negative_training = female_data_original_training[female_data_original_training['rating'] == -1]\n",
    "# calculate current gender ratio (male:female) in training dataset\n",
    "print(\"current number of male data (training): \" + str(len(male_data_original_training)))\n",
    "print(\"current number of female data (training): \" + str(len(female_data_original_training)))\n",
    "print(\"current gender ratio (training): 1 - \" + str(len(male_data_original_training) / len(female_data_original_training)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "# male and female data processing (in embedding and tf-idf dataset)\n",
    "\n",
    "# separate training and validation dataset in male and female on embedding set\n",
    "training_logical_male = (train_data_original['dr_id_gender'] == 1)\n",
    "training_logical_female = (train_data_original['dr_id_gender'] == 0)\n",
    "valid_logical_male = (val_data_original['dr_id_gender'] == 1)\n",
    "valid_logical_female = (val_data_original['dr_id_gender'] == 0)\n",
    "\n",
    "embedding_training_male = train_embeddings[training_logical_male]\n",
    "embedding_training_female = train_embeddings[training_logical_female]\n",
    "embedding_valid_male = valid_embeddings[valid_logical_male]\n",
    "embedding_valid_female = valid_embeddings[valid_logical_female]\n",
    "\n",
    "tfidf_training_male = train_tfidf[training_logical_male]\n",
    "tfidf_training_female = train_tfidf[training_logical_female]\n",
    "tfidf_valid_male = valid_tfidf[valid_logical_male]\n",
    "tfidf_valid_female = valid_tfidf[valid_logical_female]\n",
    "# print(tfidf_training_male)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive ratio of male: 0.7257254464285714\n",
      "negative ratio of male: 0.27427455357142855\n",
      "positive ratio of female: 0.7381429525718103\n",
      "negative ratio of female: 0.2618570474281897\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# demonstrate ratio of positive/negative comparison in male and female\n",
    "# both positive and negative ratio is very similar\n",
    "\n",
    "bar_width = 0.35\n",
    "labels = ['male', 'female']\n",
    "male_positive_ratio = len(male_data_positive) / len(male_data_original)\n",
    "male_negative_ratio = len(male_data_negative) / len(male_data_original)\n",
    "female_positive_ratio = len(female_data_positive) / len(female_data_original)\n",
    "female_negative_ratio = len(female_data_negative) / len(female_data_original)\n",
    "print(\"positive ratio of male: \" + str(male_positive_ratio))\n",
    "print(\"negative ratio of male: \" + str(male_negative_ratio))\n",
    "print(\"positive ratio of female: \" + str(female_positive_ratio))\n",
    "print(\"negative ratio of female: \" + str(female_negative_ratio))\n",
    "\n",
    "positive_data_ratio = [male_positive_ratio, female_positive_ratio]\n",
    "negative_data_ratio = [male_negative_ratio, female_negative_ratio]\n",
    "index = np.arange(len(labels))\n",
    "bar1_ratio = plt.bar(index, positive_data_ratio, bar_width, label='positive ratio', color='gray')\n",
    "bar2_ratio = plt.bar(index + bar_width, negative_data_ratio, bar_width, label='negative ratio', color='black')\n",
    "plt.title('Ratio of positive and negative reviews each gender group')\n",
    "plt.xlabel('gender label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(index + bar_width / 2, labels)  # positioning of group labels in the middle\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test new data set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf Multinomial Naive Bayes new male, training time: 0.0624542236328125\n",
      "tf-idf Multinomial Naive Bayes new male, predicting time: 0.015613317489624023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.65      0.75       983\n",
      "           1       0.88      0.97      0.92      2601\n",
      "\n",
      "    accuracy                           0.88      3584\n",
      "   macro avg       0.89      0.81      0.84      3584\n",
      "weighted avg       0.88      0.88      0.88      3584\n",
      "\n",
      "tf-idf Gaussian Naive Bayes new male, training time: 0.35928988456726074\n",
      "tf-idf Gaussian Naive Bayes new male, predicting time: 0.0641322135925293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.89      0.78       983\n",
      "           1       0.95      0.85      0.90      2601\n",
      "\n",
      "    accuracy                           0.86      3584\n",
      "   macro avg       0.82      0.87      0.84      3584\n",
      "weighted avg       0.88      0.86      0.87      3584\n",
      "\n",
      "tf-idf Multinomial Naive Bayes new female, training time: 0.031248092651367188\n",
      "tf-idf Multinomial Naive Bayes new female, predicting time: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.73      0.78       392\n",
      "           1       0.91      0.95      0.93      1105\n",
      "\n",
      "    accuracy                           0.89      1497\n",
      "   macro avg       0.87      0.84      0.85      1497\n",
      "weighted avg       0.89      0.89      0.89      1497\n",
      "\n",
      "tf-idf Gaussian Naive Bayes new female, training time: 0.1874558925628662\n",
      "tf-idf Gaussian Naive Bayes new female, predicting time: 0.046864986419677734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.88      0.78       392\n",
      "           1       0.95      0.87      0.91      1105\n",
      "\n",
      "    accuracy                           0.87      1497\n",
      "   macro avg       0.83      0.87      0.85      1497\n",
      "weighted avg       0.89      0.87      0.88      1497\n",
      "\n",
      "embeddings Gaussian Naive Bayes new male, training time: 0.29888057708740234\n",
      "embeddings Gaussian Naive Bayes new male, predicting time: 0.06248927116394043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.90      0.79       983\n",
      "           1       0.96      0.86      0.91      2601\n",
      "\n",
      "    accuracy                           0.87      3584\n",
      "   macro avg       0.83      0.88      0.85      3584\n",
      "weighted avg       0.89      0.87      0.87      3584\n",
      "\n",
      "embedding Gaussian Naive Bayes new female, training time: 0.10938620567321777\n",
      "embedding Gaussian Naive Bayes new female, predicting time: 0.031208038330078125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.89      0.79       392\n",
      "           1       0.96      0.87      0.91      1105\n",
      "\n",
      "    accuracy                           0.88      1497\n",
      "   macro avg       0.83      0.88      0.85      1497\n",
      "weighted avg       0.89      0.88      0.88      1497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MNB and GNB test on new datasets\n",
    "\n",
    "# tf-idf\n",
    "# MNB, new male tf-idf alpha 0.9\n",
    "# tfidf_training_male_sampled = tfidf_training_male.sample(n=3584, random_state=42)\n",
    "# tfidf_valid_male_sampled = tfidf_valid_male.sample(n=3584, random_state=42)\n",
    "# sampled_indices = tfidf_valid_male_sampled.index\n",
    "# val_labels_sampled = val_labels[sampled_indices]\n",
    "MNB_clf = MultinomialNB(alpha=0.9)\n",
    "start = time.time()\n",
    "MNB_clf.fit(tfidf_training_male, training_male_label)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes new male, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MNB_clf.predict(tfidf_valid_male)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes new male, predicting time: \" + str(end - start))\n",
    "print(classification_report(val_male_label, valid_pred))\n",
    "\n",
    "# # GNB, new male tf-idf\n",
    "GNB_clf = GaussianNB()\n",
    "start = time.time()\n",
    "GNB_clf.fit(tfidf_training_male, training_male_label)\n",
    "end = time.time()\n",
    "print(\"tf-idf Gaussian Naive Bayes new male, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = GNB_clf.predict(tfidf_valid_male)\n",
    "end = time.time()\n",
    "print(\"tf-idf Gaussian Naive Bayes new male, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_male_label, valid_pred))\n",
    "\n",
    "# MNB, new female tf-idf alpha 0.9\n",
    "# tfidf_training_female_sampled = tfidf_training_female.sample(n=1497, random_state=42)\n",
    "# tfidf_valid_female_sampled = tfidf_valid_female.sample(n=1497, random_state=42)\n",
    "# sampled_indices = tfidf_valid_female_sampled.index\n",
    "# val_labels_sampled = val_labels[sampled_indices]\n",
    "MNB_clf = MultinomialNB(alpha=0.9)\n",
    "start = time.time()\n",
    "MNB_clf.fit(tfidf_training_female, training_female_label)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes new female, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MNB_clf.predict(tfidf_valid_female)\n",
    "end = time.time()\n",
    "print(\"tf-idf Multinomial Naive Bayes new female, predicting time: \" + str(end - start))\n",
    "print(classification_report(val_female_label, valid_pred))\n",
    "\n",
    "# GNB, new female tf-idf\n",
    "GNB_clf = GaussianNB()\n",
    "start = time.time()\n",
    "GNB_clf.fit(tfidf_training_female, training_female_label)\n",
    "end = time.time()\n",
    "print(\"tf-idf Gaussian Naive Bayes new female, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = GNB_clf.predict(tfidf_valid_female)\n",
    "end = time.time()\n",
    "print(\"tf-idf Gaussian Naive Bayes new female, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_female_label, valid_pred))\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "# embedding\n",
    "# GNB, male embedding\n",
    "# embedding_training_male_sampled = embedding_training_male.sample(n=3584, random_state=42)\n",
    "# embedding_valid_male_sampled = embedding_valid_male.sample(n=3584, random_state=42)\n",
    "# sampled_indices = embedding_valid_male_sampled.index\n",
    "# val_labels_sampled = val_labels[sampled_indices]\n",
    "GNB_clf = GaussianNB()\n",
    "start = time.time()\n",
    "GNB_clf.fit(embedding_training_male, training_male_label)\n",
    "end = time.time()\n",
    "print(\"embeddings Gaussian Naive Bayes new male, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = GNB_clf.predict(embedding_valid_male)\n",
    "end = time.time()\n",
    "print(\"embeddings Gaussian Naive Bayes new male, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_male_label, valid_pred))\n",
    "\n",
    "# GNB, female embedding\n",
    "# embedding_training_female_sampled = embedding_training_female.sample(n=1497, random_state=42)\n",
    "# embedding_valid_female_sampled = embedding_valid_female.sample(n=1497, random_state=42)\n",
    "# sampled_indices = embedding_valid_female_sampled.index\n",
    "# val_labels_sampled = val_labels[sampled_indices]\n",
    "GNB_clf = GaussianNB()\n",
    "start = time.time()\n",
    "GNB_clf.fit(embedding_training_female, training_female_label)\n",
    "end = time.time()\n",
    "print(\"embedding Gaussian Naive Bayes new female, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = GNB_clf.predict(embedding_valid_female)\n",
    "end = time.time()\n",
    "print(\"embedding Gaussian Naive Bayes new female, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_female_label, valid_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings Logistic Regression (male), training time: 1.126455545425415\n",
      "embeddings Logistic Regression (male), predicting time: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.87      0.86       983\n",
      "           1       0.95      0.94      0.95      2601\n",
      "\n",
      "    accuracy                           0.92      3584\n",
      "   macro avg       0.90      0.91      0.90      3584\n",
      "weighted avg       0.92      0.92      0.92      3584\n",
      "\n",
      "embeddings Logistic Regression (female), training time: 0.4252195358276367\n",
      "embeddings Logistic Regression (female), predicting time: 0.015585899353027344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.90      0.86       392\n",
      "           1       0.96      0.93      0.95      1105\n",
      "\n",
      "    accuracy                           0.92      1497\n",
      "   macro avg       0.89      0.91      0.90      1497\n",
      "weighted avg       0.93      0.92      0.92      1497\n",
      "\n",
      "tf-idf Logistic Regression (male), training time: 1.2306580543518066\n",
      "tf-idf Logistic Regression (male), predicting time: 0.015620946884155273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.84      0.84       983\n",
      "           1       0.94      0.94      0.94      2601\n",
      "\n",
      "    accuracy                           0.91      3584\n",
      "   macro avg       0.89      0.89      0.89      3584\n",
      "weighted avg       0.91      0.91      0.91      3584\n",
      "\n",
      "tf-idf Logistic Regression (female), training time: 0.4094974994659424\n",
      "tf-idf Logistic Regression (female), predicting time: 0.01561737060546875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.85      0.85       392\n",
      "           1       0.95      0.94      0.94      1105\n",
      "\n",
      "    accuracy                           0.92      1497\n",
      "   macro avg       0.89      0.90      0.90      1497\n",
      "weighted avg       0.92      0.92      0.92      1497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin(male) Logistic Regression(penalty l1), training time: 3.8581392765045166\n",
      "origin(male) Logistic Regression(penalty l1), predicting time: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.27      1.00      0.43       983\n",
      "           1       0.00      0.00      0.00      2601\n",
      "\n",
      "    accuracy                           0.27      3584\n",
      "   macro avg       0.14      0.50      0.22      3584\n",
      "weighted avg       0.08      0.27      0.12      3584\n",
      "\n",
      "origin(female) Logistic Regression(penalty l1), training time: 1.6086673736572266\n",
      "origin(female) Logistic Regression(penalty l1), predicting time: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.26      1.00      0.42       392\n",
      "           1       0.00      0.00      0.00      1105\n",
      "\n",
      "    accuracy                           0.26      1497\n",
      "   macro avg       0.13      0.50      0.21      1497\n",
      "weighted avg       0.07      0.26      0.11      1497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# logistic new datasets\n",
    "\n",
    "# embedding male\n",
    "# embedding_training_male_sampled = embedding_training_male.sample(n=3584, random_state=42)\n",
    "# embedding_valid_male_sampled = embedding_valid_male.sample(n=3584, random_state=42)\n",
    "# sampled_indices = embedding_valid_male_sampled.index\n",
    "# val_labels_sampled = val_labels[sampled_indices]\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "LRclf.fit(embedding_training_male, training_male_label)\n",
    "end = time.time()\n",
    "print(\"embeddings Logistic Regression (male), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(embedding_valid_male)\n",
    "end = time.time()\n",
    "print(\"embeddings Logistic Regression (male), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_male_label, valid_pred))\n",
    "\n",
    "# embedding female\n",
    "# embedding_training_female_sampled = embedding_training_female.sample(n=1497, random_state=42)\n",
    "# embedding_valid_female_sampled = embedding_valid_female.sample(n=1497, random_state=42)\n",
    "# sampled_indices = embedding_valid_female_sampled.index\n",
    "# val_labels_sampled = val_labels[sampled_indices]\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "LRclf.fit(embedding_training_female, training_female_label)\n",
    "end = time.time()\n",
    "print(\"embeddings Logistic Regression (female), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(embedding_valid_female)\n",
    "end = time.time()\n",
    "print(\"embeddings Logistic Regression (female), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_female_label, valid_pred))\n",
    "\n",
    "# tf-idf male\n",
    "# tfidf_training_male_sampled = tfidf_training_male.sample(n=3584, random_state=42)\n",
    "# tfidf_valid_male_sampled = tfidf_valid_male.sample(n=3584, random_state=42)\n",
    "# sampled_indices = tfidf_valid_male_sampled.index\n",
    "# val_labels_sampled = val_labels[sampled_indices]\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "LRclf.fit(tfidf_training_male, training_male_label)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (male), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(tfidf_valid_male)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (male), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_male_label, valid_pred))\n",
    "\n",
    "# tf-idf female\n",
    "# tfidf_training_female_sampled = tfidf_training_female.sample(n=1497, random_state=42)\n",
    "# tfidf_valid_female_sampled = tfidf_valid_female.sample(n=1497, random_state=42)\n",
    "# sampled_indices = tfidf_valid_female_sampled.index\n",
    "# val_labels_sampled = val_labels[sampled_indices]\n",
    "LRclf = LogisticRegression(random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "LRclf.fit(tfidf_training_female, training_female_label)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (female), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(tfidf_valid_female)\n",
    "end = time.time()\n",
    "print(\"tf-idf Logistic Regression (female), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_female_label, valid_pred))\n",
    "\n",
    "# origin male\n",
    "LRclf = LogisticRegression(penalty='l1', C=1.0, solver='saga', random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "LRclf.fit(male_data_original_training, training_male_label)\n",
    "end = time.time()\n",
    "print(\"origin(male) Logistic Regression(penalty l1), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(male_data_original)\n",
    "end = time.time()\n",
    "print(\"origin(male) Logistic Regression(penalty l1), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_male_label, valid_pred))\n",
    "\n",
    "# origin female\n",
    "LRclf = LogisticRegression(penalty='l1', C=1.0, solver='saga', random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "LRclf.fit(female_data_original_training, training_female_label)\n",
    "end = time.time()\n",
    "print(\"origin(female) Logistic Regression(penalty l1), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = LRclf.predict(female_data_original)\n",
    "end = time.time()\n",
    "print(\"origin(female) Logistic Regression(penalty l1), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_female_label, valid_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf(male) KNN, training time: 0.09370255470275879\n",
      "tfidf(male) KNN, predicting time: 4.556760787963867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.62      0.70       983\n",
      "           1       0.87      0.94      0.90      2601\n",
      "\n",
      "    accuracy                           0.85      3584\n",
      "   macro avg       0.83      0.78      0.80      3584\n",
      "weighted avg       0.85      0.85      0.85      3584\n",
      "\n",
      "tfidf(female) KNN, training time: 0.10538363456726074\n",
      "tfidf(female) KNN, predicting time: 1.0628578662872314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.60      0.67       392\n",
      "           1       0.87      0.93      0.90      1105\n",
      "\n",
      "    accuracy                           0.84      1497\n",
      "   macro avg       0.81      0.77      0.78      1497\n",
      "weighted avg       0.84      0.84      0.84      1497\n",
      "\n",
      "embedding(male) KNN, training time: 0.16371560096740723\n",
      "embedding(male) KNN, predicting time: 3.065330743789673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.69      0.76       983\n",
      "           1       0.89      0.95      0.92      2601\n",
      "\n",
      "    accuracy                           0.88      3584\n",
      "   macro avg       0.87      0.82      0.84      3584\n",
      "weighted avg       0.88      0.88      0.88      3584\n",
      "\n",
      "embedding(female) KNN, training time: 0.0818336009979248\n",
      "embedding(female) KNN, predicting time: 0.6965665817260742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.75      0.78       392\n",
      "           1       0.91      0.94      0.93      1105\n",
      "\n",
      "    accuracy                           0.89      1497\n",
      "   macro avg       0.87      0.85      0.85      1497\n",
      "weighted avg       0.89      0.89      0.89      1497\n",
      "\n",
      "origin(male) KNN, training time: 0.01562190055847168\n",
      "origin(male) KNN, predicting time: 1.2339582443237305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       983\n",
      "           1       0.73      1.00      0.84      2601\n",
      "\n",
      "    accuracy                           0.73      3584\n",
      "   macro avg       0.36      0.50      0.42      3584\n",
      "weighted avg       0.53      0.73      0.61      3584\n",
      "\n",
      "origin(female) KNN, training time: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin(female) KNN, predicting time: 0.3072056770324707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       392\n",
      "           1       0.74      1.00      0.85      1105\n",
      "\n",
      "    accuracy                           0.74      1497\n",
      "   macro avg       0.37      0.50      0.42      1497\n",
      "weighted avg       0.54      0.74      0.63      1497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anacoda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# KNN new datasets\n",
    "\n",
    "# KNN tf-idf male\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=10, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(tfidf_training_male, training_male_label)\n",
    "end = time.time()\n",
    "print(\"tfidf(male) KNN, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(tfidf_valid_male)\n",
    "end = time.time()\n",
    "print(\"tfidf(male) KNN, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_male_label, valid_pred))\n",
    "\n",
    "# KNN tf-idf female\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=10, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(tfidf_training_female, training_female_label)\n",
    "end = time.time()\n",
    "print(\"tfidf(female) KNN, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(tfidf_valid_female)\n",
    "end = time.time()\n",
    "print(\"tfidf(female) KNN, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_female_label, valid_pred))\n",
    "\n",
    "# KNN embedding male\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=10, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(embedding_training_male, training_male_label)\n",
    "end = time.time()\n",
    "print(\"embedding(male) KNN, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(embedding_valid_male)\n",
    "end = time.time()\n",
    "print(\"embedding(male) KNN, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_male_label, valid_pred))\n",
    "\n",
    "# KNN embedding female\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=10, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(embedding_training_female, training_female_label)\n",
    "end = time.time()\n",
    "print(\"embedding(female) KNN, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(embedding_valid_female)\n",
    "end = time.time()\n",
    "print(\"embedding(female) KNN, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_female_label, valid_pred))\n",
    "\n",
    "# KNN origin male\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=10, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(male_data_original_training, training_male_label)\n",
    "end = time.time()\n",
    "print(\"origin(male) KNN, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(male_data_original)\n",
    "end = time.time()\n",
    "print(\"origin(male) KNN, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_male_label, valid_pred))\n",
    "\n",
    "# KNN origin female\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=10, weights='distance', metric='cosine')\n",
    "start = time.time()\n",
    "KNNclf.fit(female_data_original_training, training_female_label)\n",
    "end = time.time()\n",
    "print(\"origin(female) KNN, training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = KNNclf.predict(female_data_original)\n",
    "end = time.time()\n",
    "print(\"origin(female) KNN, predicting time: \" + str(end-start))\n",
    "print(classification_report(val_female_label, valid_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings MLPClassifier (male), training time: 138.21787476539612\n",
      "embeddings MLPClassifier (male), predicting time: 0.06443476676940918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.81      0.84       983\n",
      "           1       0.93      0.95      0.94      2601\n",
      "\n",
      "    accuracy                           0.91      3584\n",
      "   macro avg       0.90      0.88      0.89      3584\n",
      "weighted avg       0.91      0.91      0.91      3584\n",
      "\n",
      "embeddings MLPClassifier (female), training time: 81.72404193878174\n",
      "embeddings MLPClassifier (female), predicting time: 0.017832517623901367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.89      0.87       392\n",
      "           1       0.96      0.94      0.95      1105\n",
      "\n",
      "    accuracy                           0.93      1497\n",
      "   macro avg       0.90      0.92      0.91      1497\n",
      "weighted avg       0.93      0.93      0.93      1497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLP new datasets\n",
    "\n",
    "# MPL embedding male\n",
    "MLPclf = MLPClassifier(hidden_layer_sizes=300, random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "MLPclf.fit(embedding_training_male, training_male_label)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (male), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MLPclf.predict(embedding_valid_male)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (male), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_male_label, valid_pred))\n",
    "\n",
    "# MPL embedding female\n",
    "MLPclf = MLPClassifier(hidden_layer_sizes=300, random_state=42, max_iter=800)\n",
    "start = time.time()\n",
    "MLPclf.fit(embedding_training_female, training_female_label)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (female), training time: \" + str(end-start))\n",
    "start = time.time()\n",
    "valid_pred = MLPclf.predict(embedding_valid_female)\n",
    "end = time.time()\n",
    "print(\"embeddings MLPClassifier (female), predicting time: \" + str(end-start))\n",
    "print(classification_report(val_female_label, valid_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "# kaggle\n",
    "\n",
    "MLPclf = MLPClassifier(hidden_layer_sizes=300, random_state=42, max_iter=800)\n",
    "\n",
    "MLPclf.fit(train_embeddings, train_labels)\n",
    "valid_pred = MLPclf.predict(test_embeddings)\n",
    "print(len(valid_pred))\n",
    "assert test_data_original_hiddenComment.shape[0] == len(valid_pred)\n",
    "\n",
    "fout = open(\"kaggle_test.csv\", \"w\")\n",
    "fout.write(\"id, rating\\n\")\n",
    "for idx, pred in enumerate(valid_pred):\n",
    "    fout.write(f\"{idx},{pred}\\n\")\n",
    "fout.close()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
